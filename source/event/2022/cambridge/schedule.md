---
title: "2022 IIIF Annual Conference Schedule"
layout: spec
page: overview
banner: true 
breadcrumbs:
  - label: All Events
    link: '{{ site.root_url }}/event/'
  - label: Cambridge 2022
    link: '{{ site.root_url }}/event/2022/cambridge/'
---





## 2022 IIIF Annual Conference Schedule

The outline schedules of the [showcase][showcase] and conference are available below, with specific conference presentations and abstracts listed further down. The exact timing of each day’s schedule is still subject to change.

### **Register**

* Please register for both the showcase (free and open to all) and conference using Conftool. Payment must be submitted following your registration via Paypal using a credit card number, or via check. You can register [here](https://www.conftool.org/iiif2022/index.php?page=index).


* Registration for the IIIF showcase is free.
* Registration for the conference is $375 for a general ticket, $240 for a [consortium members]({{ site.root_url | absolute_url }}/community/consortium) ticket, and $100 for a student/discount ticket.

### **Sponsors**

We are offering sponsorship for the 2022 IIIF conference and the benefits and costs can be seen on the [sponsorship page]({{ site.root_url | absolute_url }}/event/2022/cambridge/sponsorship). If you are interested in becoming a sponsor please contact [admin@iiif.io](mailto:admin@iiif.io).

The IIIF Annual Conference is generously supported by the following Conference Sponsors:


**Silver sponsors**  <br>

<a href="https://www.oclc.org/" style="border-bottom: none"><img src="{{ site.root_url | absolute_url }}/assets/event/sponsors/oclc_logo.png" alt='OCLC logo' style="width: 300px"></a>
<a href="https://www.performantsoftware.com" style="border-bottom: none"><img src="{{ site.root_url | absolute_url }}/assets/event/sponsors/performant_logo_300w.png" alt='performant software logo' style="height: 160px"></a>

**Bronze sponsors**  <br>

<a href="https://www.lunaimaging.com/" style="border-bottom: none"><img src="{{ site.root_url | absolute_url }}/assets/event/sponsors/LUNALogo_300px.png" alt='OCLC logo' style="width: 300px"></a>


## June 6 
### IIIF Showcase

The [IIIF showcase][showcase] is free and open to the public. Attend this event to learn more about IIIF, including an overview of what it does, use cases, how you can implement IIIF at your institution, and how you can contribute to the community.

#### Showcase Schedule 

See the [showcase][showcase] page for the detailed schedule of speakers.

* 12pm-1pm: Check-in opens for showcase and conference registrants
* 1pm-5pm: Showcase (including coffee break)
  

#### IIIF Consortium reception

* 6-8pm: Consortium reception (open to all attendees affiliated with a [IIIF Consortium member institution]({{ site.root_url | absolute_url }}/community/consortium/members), to be held in an outdoor, covered location)


## June 7

### Conference day 1

The IIIF conference is open to advanced registrants.



* 8am-9am: Check-in
* 9am-12pm: [Opening plenary and sessions](#session1)
* 12pm-1:30pm: Lunch
* 1:30pm-3:30pm: [Sessions (see presentations listed below)](#session2)
* 3:30pm - 4pm: Break
* 4pm-5:30pm: [Sessions (see presentations listed below)](#session3)
* 7pm-9pm: General conference reception, open to all registered participants (to be held outdoors on the Harvard quad, under a tent in case of rain)


## June 8

### Conference day 2

The IIIF conference is open to advanced registrants.



* 9am-12pm: [Sessions (see presentations listed below)](#session4)
* 12pm-1:30pm: Lunch
* 1:30pm-3:30pm: [Sessions (see presentations listed below)](#session5)
* 3:30pm - 5:00pm: Tour of the Leventhal Map and Education Center, Boston Public Library (limited to 30 attendees.)

---

<style>
  .paper_time_value {font-weight: bold;}
  .paper_abstract {
    /*display: none;*/
    padding: 0 0 0 10%;
  }
  .paper_title {font-size: 120%;}
</style>

## Conference Presentations

<div class="topline_printonly left"><div class='navbar_breadcrumb' style='float:none; width:auto; padding:8px 0 3px 0; border: 0; border-top: 1px solid #666666;'>

<a id='session1' name='session1'></a><h3>Block 1</h3>
<h3>Tuesday, 07/June/2022: 9:00am - 12:00pm</h3>
</div>
<div class='topline_gray' style='padding:3px;'>
<div class="paper"><span class="paper_time_value">9:00am - 9:30am</span><br /><p class="paper_title">Welcome and opening remarks</p>
<p class="paper_author"> <u>Josh Hadro</u></p>

<p class="paper_organisation">IIIF, United States of America</p>

<div ><div class="paper">

<p class="paper_abstract">Josh Hadro, Managing Director of the IIIF Consortium, welcomes attendees to the event in partnership with Harvard University and MIT.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">9:30am - 10:00am</span><br /><p class="paper_title">State of the IIIF Universe</p>
<p class="paper_author"> <u>Josh Hadro</u></p>

<p class="paper_organisation">IIIF, United States of America</p>

<div ><div class="paper">

<p class="paper_abstract">This session will provide an update on the status of the many IIIF Community Groups currently meeting to discuss issues relating to their field of practice.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">10:00am - 10:30am</span><br /><p class="paper_title">IIIF 3D - Developing New Dimensions &amp; Technical Specification</p>
<p class="paper_author"> <u>Ronald S. Haynes</u></p>

<p class="paper_organisation">University of Cambridge, United Kingdom</p>

<div ><div class="paper">

<p class="paper_abstract">With growing, global efforts for further establishing IIIF use for 2D images and Audio/Video (A/V) data, there is increasing commitment to develop similar standards for 3D content. The IIIF 3D Community Group is collaboratively considering common challenges and potential solutions with major 3D developers and researchers, and has formed the IIIF 3D Technical Specification Group, engaging even more widely with specialists and representatives across user communities and standards bodies. The complementary work of the CG and TSG is considering ways not only to suitably extend IIIF into the 3rd (physical) dimension, but also to explore digital opportunities to try to address the concerns of decolonisation and digital/object repatriation. In addition, the group will be considering creative options to support incorporation of 2D and A/V with 3D data, enabling combinations to form digital dioramas, scene and soundscape reconstructions, and the potential to help build an inclusive metaverse. Please do join us!</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">10:30am - 11:00am</span><br /><p class="paper_title">A New Manifest Editor (and more)</p>
<p class="paper_author"> <u>Tom Crane</u>, <u>Stephen Fraser</u></p>

<p class="paper_organisation">Digirati, United Kingdom</p>

<div ><div class="paper">

<p class="paper_abstract">Why a new Manifest Editor?</p>
<p class="paper_abstract">As the use of IIIF grows, so the need for IIIF content creation tools grows.</p>
<p class="paper_abstract">Most IIIF manifests are expected to produce consistent results in standard IIIF viewers.</p>
<p class="paper_abstract">But increasingly, manifests are also being created for very specific user interfaces. An early example is Wellcome Collection’s Sleep Stories [1], from 2016. In 2017, Digirati worked on IIIF Manifest-driven narratives for the V&amp;A [2], and in 2018 for Technical University, Delft.[3]</p>
<p class="paper_abstract">This work produced a IIIF Manifest Editor [4] that in normal, default mode produces IIIF Presentation 3 Manifests, but can be extended with plugins to produce IIIF Manifests with particular structures and custom behavior properties, to drive bespoke viewing experiences - slideshows, guided viewing and the complex digital exhibition layouts seen in the Delft examples.</p>
<p class="paper_abstract">Now, in partnership with the UK Towards a National Collection project [5] and Delft University of Technology Library, we are building a new Manifest Editor framework, that can accommodate many of the use cases we have seen emerging over the last 6 years.</p>
<p class="paper_abstract">This aims to provide a general purpose tool that is:</p>
<p class="paper_abstract">- Suitable for creating general purpose manifests</p>
<p class="paper_abstract">- Great for learning IIIF concepts</p>
<p class="paper_abstract">- Configurable to create manifests for specific target environments</p>
<p class="paper_abstract">- Easily integrated into diverse production workflows</p>
<p class="paper_abstract">In this presentation, we will explore the features of Manifest Editor and look at how it can be adapted for specialist use cases.</p>
<p class="paper_abstract">Read more at https://github.com/digirati-co-uk/iiif-manifest-editor</p>
<p class="paper_abstract">- --</p>
<p class="paper_abstract">[1] https://ghp.wellcomecollection.org/annotation-viewer/quilt/</p>
<p class="paper_abstract">[2] https://medium.com/digirati-ch/reaching-into-collections-to-tell-stories-3dc32a1772af</p>
<p class="paper_abstract">[3] https://drive.google.com/file/d/1ZRXJaOYNbOD0jsOF79maKhxl5re4-2Kt/view</p>
<p class="paper_abstract">[4] https://www.youtube.com/watch?v=D8oA3rHbvPM</p>
<p class="paper_abstract">[5] https://www.nationalcollection.org.uk/</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">11:00am - 11:30am</span><br /><p class="paper_title">Change Discovery as an Agent for Statewide Discovery of Digital Assets</p>
<p class="paper_author"> <u>Emily Gore</u><sup>1</sup>, <u>Mark Baggett</u><sup>1</sup>, <u>Jeff Mixter</u><sup>2</sup></p>

<p class="paper_organisation"><sup>1</sup>University of Tennessee, United States of America; <sup>2</sup>OCLC Research</p>

<div ><div class="paper">

<p class="paper_abstract">The University of Tennessee Libraries recently discussed the limitations of metadata aggregation with our partners across the state representing the Digital Library of Tennessee. For a number of reasons, partners are interested in making full objects available instead of metadata-only discovery. This interest aligns well with the efforts of the IIIF Change Discovery Technical Working Group. UTK Libraries and our DLTN partners are evaluating the IIIF Change Discovery API as a potential solution for full-object aggregation coupled with a Blacklight discovery layer. During this presentation, UTK Libraries will discuss our test implementation of the Change Discovery API and demonstrate our statewide search of IIIF-enabled platforms. UTK Libraries has been working with OCLC Research to develop our test to ensure the inclusion of all CONTENTdm libraries in the state of TN. Jeff Mixter from OCLC will discuss the IIIF Change Discovery prototype that has been developed within OCLC Research and provide an overview on how it works and how to harvest from it.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">11:30am - 12:00pm</span><br /><p class="paper_title">Using IIIF to teach Digital Humanities: advancing digital literacy in higher education</p>
<p class="paper_author"> Davy Verbeke<sup>1,2</sup>, <u>Lise Foket</u><sup>1,2</sup>, Eef Rombaut<sup>2,3</sup>, Frederic Lamsens<sup>1</sup>, Christophe Verbruggen<sup>1,2</sup></p>

<p class="paper_organisation"><sup>1</sup>Ghent Centre for Digital Humanities (Ghent University), Belgium; <sup>2</sup>Faculty of Arts and Philosophy (Ghent University), Belgium; <sup>3</sup>Antwerp School of Education (University of Antwerp)</p>

<div ><div class="paper">

<p class="paper_abstract">The benefits of IIIF for Digital Humanities (DH) scholarship are well known: accessibility to images, metadata and annotation possibilities, and ample visual display options. However, whilst the cultural heritage sector and DH research centers have broadly adopted IIIF, its integration into teaching practices has remained rather limited. At the same time, DH scholars are calling for more extensive adoption of their field within Humanities scholarship. Teaching DH requires a hybrid approach covering various digital tools to assist research, educational, and science communication purposes, which is often accompanied by underscoring the usefulness, openness, diversity, and collaboration-possibilities of the tools in question (Batterhill &amp; Ross, 2017). Rather than learn a fixed set of computational hard skills, students need to contextualize digital technologies, adopt a tool-critical attitude and apply them to a domain-specific context (Armaselu, 2021; Kuhn, 2019).</p>
<p class="paper_abstract">IIIF is therefore a common denominator in Ghent Centre For Digital Humanities’ educational innovation project to structurally embed DH and sustainably enhance digital competences within the Faculty of Arts and Philosophy, including teacher education. Not only does IIIF’s flexibility and compliance with various DH applications greatly assist a provisioned hybrid approach of teaching, but the open image-standard also ‘stitches together technology’ for DH overall (Emanuel, 2018). This presentation, which is based on various classroom-case studies, focus group discussions, and questionnaires, explores how IIIF helped foster a shared faculty-wide framework for basic and advanced digital competences of students, (prospective) teachers, and faculty staff. Ranging from teacher education to art history and Lingala language, diverse courses found common ground in IIIF and compatible tools, such as Madoc, Omeka S, Storiiies and Exhibit.so. Blended learning modules that combined workshops, video tutorials, manuals, best practices, and literature provided assistance during the courses. This presentation discusses how IIIF allowed teachers and students to relate DH to their domain-specific knowledge, and how this resulted in a more widespread integration of both IIIF and DH across Ghent University.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
</div>
<div class='navbar_breadcrumb' style='float:none; width:auto; padding:8px 0 3px 0; border: 0; border-top: 1px solid #666666;'>
<a id='session2' name='session2'></a><h3>Block 2</h3>
<h3>Tuesday, 07/June/2022: 1:30pm - 3:30pm</h3>
</div>
<div class='topline_gray' style='padding:3px;'>
<div class="paper"><span class="paper_time_value">1:30pm - 2:00pm</span><br /><p class="paper_title">IIIF V3 Manifests with Annotations in Archipelago</p>
<p class="paper_author"> <u>Diego Alberto Pino Navarro</u>, <u>Allison Kelly Lund</u></p>

<p class="paper_organisation">Metropolitan New York Library Council, United States of America</p>

<div ><div class="paper">

<p class="paper_abstract">Archipelago is an open source repository system developed and supported by the Metropolitan New York Library Council (METRO). Archipelago leverages Drupal’s core content management and custom Archipelago components, the Strawberryfield modules, to form a flexible and extensible digital repository system. All data, including metadata, for digital objects and collections is stored in JSON, and can be cast into different metadata schemas and displays depending on institutional and community needs. IIIF APIs and IIIF compliant viewer customizations, including IIIF tile source and W3C Web Annotations, are woven into Archipelago’s architecture and functionality.</p>
<p class="paper_abstract">During this presentation, participants will learn about Archipelago’s IIIF Media Formatter and how collaborative W3C Web Annotations work. This work is based on Open SeaDragon and Annotorious plus a custom REST API. Participants will be walked through an explanation of how the Media Formatter references Images from a Digital Object’s JSON Strawberryfield, using IIIF to request and precompute correct media and sizes to expose to Open SeaDragon. Presenters will explain how the integration of Rainer Simon’s Annotorious enables the direct creation and modification of WebAnnotations in Archipelago. Participants will then see a live demonstration of Annotations being added to a Digital Object, and review how these Annotations are being stored and rendered on the fly on the corresponding IIIF Manifest, displayed in Viewers, and also exposed as machinable endpoints. Participants will be invited to interact with the same freely-accessible Archipelago instance and resources on their own following the presentation.</p>
<p class="paper_abstract">In harmony with IIIF’s goals and guiding principles, Archipelago&#39;s primary focus is to serve greater repositories, libraries, archives, museums, and cultural heritage communities by providing an adaptable, consistent, and unified way of describing, storing, linking, and exposing metadata and media assets. This presentation is for all practitioners (including metadata librarians/professionals, repository managers, and data producers) involved with metadata modeling, creation, and management in repository environments, with a focus on learning and working with IIIF manifests and Annotations.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">2:00pm - 2:30pm</span><br /><p class="paper_title">From text to image: linking TEI-XML and IIIF via expert sourced annotations and IIIF Change Discovery</p>
<p class="paper_author"> <u>Matthew McGrattan</u></p>

<p class="paper_organisation">Digirati, United Kingdom</p>

<div ><div class="paper">

<p class="paper_abstract">Many institutions have both:</p>
<p class="paper_abstract">1. transcripts for manuscripts or printed books, encoded as TEI-XML</p>
<p class="paper_abstract">2. digital surrogates for those same manuscripts or printed books, provided as IIIF</p>
<p class="paper_abstract">In ideal world, it would be possible to display IIIF and TEI-XML side by side in the same discovery environment, using a shared model for document structure to drive navigation for both IIIF and TEI-XML, so that users, can, for example, compare different witnesses to the same passage of text or read text and view images together. However, IIIF surrogates and TEI-XML encoded texts have often been created at different times, by different teams, as part of different workflows and there may not be identifiers shared across both data models that facilitate machine linking between text and image. In the absence of machine methods for linking, manually linking text with image is often a labour intensive process which requires expert knowledge of IIIF, or TEI-XML, or both. In this presentation, I will present one approach to resolving this problem, in which TEI-XML is used as the source of truth for text and document structure, and this text and document structure is fed—via a machine readable API—into a crowdsourcing environment in which expert users can link text, document structure and IIIF resources together without knowing anything about the underlying IIIF or TEI representations of the manuscript(s) in question. The eventual output of this process is discoverable via the IIIF Change Discovery API, and transformed into manifests with valid IIIF Ranges that reflect the underlying structure of theTEI-XML and which can be used to:</p>
<p class="paper_abstract">* find all of the witnesses to a particular text</p>
<p class="paper_abstract">* navigate directly to a particular section of one or more manuscripts</p>
<p class="paper_abstract">* display text and image side-by-side</p>
<p class="paper_abstract">I will demonstrate the workflow for content creation, and the search and discovery environment that can be used to search and browse texts and images together.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">2:30pm - 3:00pm</span><br /><p class="paper_title">Etu - An open source image centric IIIF universal adaptor</p>
<p class="paper_author"> <u>Jie Song</u></p>

<p class="paper_organisation">IntelliJourney, China, People&#39;s Republic of</p>

<div ><div class="paper">

<p class="paper_abstract">Considering the spectrum of IIIF user privacy preference, there are two ends that are not adequately served with current IIIF open source software community. One are those who are extremely sensitive about the image content, thus, prefer to leave everything in his/her hard disc. Another are those who care nothing about the content and wish those images could be spread as wide as possible and preserved as long as possible. Etu managed to take care of these two extremes and developed a unique image centric way to enable IIIF from hard disc images with only a couple of command lines. Our goal is to preserve the legacy image organization as much as possible and shield the end user with the complex details as setting up image server, presentation server and so on. The software is the result of collaboration work of IIIF China community members and we are glad to share it with the global community and help the adaption of IIIF in the wider spectrum regardless of user privacy preference.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">3:00pm - 3:30pm</span><br /><p class="paper_title">USE ME: progressive integration of IIIF with new software services at the Getty</p>
<p class="paper_author"> <u>Stefano Cossu</u>, <u>David Newbury</u></p>

<p class="paper_organisation">J. P. Getty Trust, United States of America</p>

<div ><div class="paper">

<p class="paper_abstract">Two years into the launch of an institution-wide IIIF delivery system and the related ETL pipelines to generate IIIF master images and manifests, two ongoing challenges have been unfolding in the broader Getty Digital development plans: making use of these IIIF services by default, and consequently, improving those services in a continuous fashion.</p>
<p class="paper_abstract">This 20-minute presentation will offer an overview of the integration of various Getty software development projects with the existing IIIF and Linked Open Data infrastructure, including our public LOD access endpoints, data analysis and annotation projects, and public-facing websites and research tools. The goal is to highlight how Getty Digital has come past the initial investment of building infrastructure and beginning to reap the long-term benefits of such investment.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
</div>
<div class='navbar_breadcrumb' style='float:none; width:auto; padding:8px 0 3px 0; border: 0; border-top: 1px solid #666666;'>
<a id='session3' name='session3'></a><h3>Block 3</h3>
<h3>Tuesday, 07/June/2022: 3:30pm - 5:30pm</h3>
</div>
<div class='topline_gray' style='padding:3px;'>
<div class="paper"><span class="paper_time_value">4:00pm - 4:30pm</span><br /><p class="paper_title">Exhibit: easy-to-use tools for promoting engagement and learning with your online digital collections.</p>
<p class="paper_author"> <u>Edward Silverton</u></p>

<p class="paper_organisation">Mnemoscene, United Kingdom</p>

<div ><div class="paper">

<p class="paper_abstract">Compounded by the Covid-19 pandemic, GLAM organisations have in recent years been facing outreach challenges in an increasingly competitive digital attention economy.</p>
<p class="paper_abstract">Exhibit (exhibit.so) is a user-friendly tool for promoting engagement and learning with your online digital collections. Built using the Universal Viewer to display IIIF content, users can create presentations, tell stories, craft quizzes, and more, using high-resolution images and 3D models.</p>
<p class="paper_abstract">Developed by Mnemoscene, the first iteration in 2021 responded directly to The University of St Andrew’s need to engage students with their digital collections during the Covid-19 lockdown. Since then, with support from the Universal Viewer Steering group and feedback from a growing number of adopters including the British Library and Royal Pavilion and Museums Trust, a range of new features and a sustainability strategy have been developed.</p>
<p class="paper_abstract">From individuals, to large institutions, we’ll discuss how you can get started with Exhibit and share plans for future development.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">4:30pm - 5:00pm</span><br /><p class="paper_title">Using IIIF Images in Visual Essays</p>
<p class="paper_author"> <u>Ron Snyder</u></p>

<p class="paper_organisation">ITHAKA, United States of America</p>

<div ><div class="paper">

<p class="paper_abstract">This presentation will provide an overview of an online toolset enabling the creation of interactive Visual Essays using images available from image sharing sites such as Wikimedia Commons, Flickr, and JSTOR Community Collections.</p>
<p class="paper_abstract">The toolset includes:</p>
<p class="paper_abstract">- Semantic search for finding open access images using the Wikidata &#39;depicts&#39; property and automatically generating IIIF manifests</p>
<p class="paper_abstract">- An annotation tool for associating W3C Web Annotations with image regions</p>
<p class="paper_abstract">- An editor for generating visual essays using an enhanced version of the Markdown language enabling IIIF images to be embedded in the image and interactions between the text and images</p>
<p class="paper_abstract">- A rendering engine for displaying the visual essays using any Markdown document as input</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">5:00pm - 5:30pm</span><br /><p class="paper_title">From Manuscript to Transcription and Back Again: Closing the Virtuous Circle with Houghton MS Lat. 5</p>
<p class="paper_author"> <u>Laura Morreale</u><sup>1</sup>, <u>Sean Gilsdorf</u><sup>2</sup></p>

<p class="paper_organisation"><sup>1</sup>Multiple Affiliations; <sup>2</sup>Harvard University</p>

<div ><div class="paper">

<p class="paper_abstract">In Spring 2022, a group of Harvard-based medievalists collaboratively transcribed and prepared a digital edition of Houghton Library MS Lat. 5, a thirteenth-century manuscript containing a copy of Conrad of Saxony’s Commentary on the Holy Places. Undertaken as part of a Harvard paleography course, the collaborative transcription and editing of Conrad’s Commentary relied principally on the IIIF-compliant images that were first created, then cataloged, and now housed at the institution’s library. To allow for group transcription, course instructor Sean Gilsdorf worked with Harvard librarian Sara Powell to upload the IIIF-compliant images to Houghton Library’s account in FromThePage, a crowdsourcing platform that easily integrates IIIF images into a collaborative transcription interface. Once the project participants had completed the transcription following protocols developed by project consultant Laura Morreale, the data was exported and then prepared for online editing and publication at a subsequent workshop with Sarah Lang (University of Graz).</p>
<p class="paper_abstract">Since this intense study of Houghton MS Lat. 5 was undertaken entirely within the Harvard environment, and interoperability is a key feature of the IIIF system, project participants were eager to share their work and make their new edition of the Commentary available to the manuscript’s future users. Despite the local nature of all the resources used to complete the project, however, common workflows do not yet exist within the Harvard ecosystem to complete the “virtuous circle”—that is, to return the annotations on the text back to the cache of IIIF-compliant images that accompany the manuscript description in the library catalog. This is neither surprising nor unexpected: the full range of IIIF capabilities has yet to be understood, much less exploited, by researchers who depend upon the technology for their work.</p>
<p class="paper_abstract">The 2022 IIIF Conference offers a valuable opportunity not simply to present this IIIF use case, but to discuss it and brainstorm solutions among members of the IIIF community gathered on the Harvard campus. We propose a talk describing this Harvard IIIF-based project, including the perspectives of the project leaders and the Harvard librarians who facilitated the work, followed by a “birds of a feather” session for conference participants working at the intersection of IIIF technology and archival studies. This latter session will solicit discussion of the problems and opportunities raised by this particular case study, and ways to address them drawn from the session participants’ own work. Our main goal is to determine how projects like ours might be brought into a productive relationship with the resources that generated them, what the IIIF “virtuous cycle” will actually look like, and how it could be accomplished in cooperation with other stakeholders on campus. More broadly, we hope that the work done with Houghton MS Lat. 5 can serve as a model for other institutions and researchers engaged in similar projects using IIIF images and tools.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">5:30pm - 6:00pm</span><br /><p class="paper_title">Creating a Scholar’s Manifest: incorporating user-contributed annotations and metadata</p>
<p class="paper_author"> <u>Debra Cashion</u><sup>1</sup>, <u>Ben Bakelaar</u><sup>2</sup></p>

<p class="paper_organisation"><sup>1</sup>St. Louis University, United States of America; <sup>2</sup>Human Experience Systems</p>

<div ><div class="paper">

<p class="paper_abstract">This presentation describes a workflow for a scholar to take a IIIF object such as a manuscript, add annotations via our implementation of Simple Annotation Server, and additionally incorporate user-contributed structured metadata using our Community Catalog tool. We combine these multiple facets of source and user-generated information into a prototyped manifest which can represent a significant amount of scholarly work. We will outline the API properties used and editorial decisions made in how we format this combined Scholar’s Manifest.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
</div>

<div class='navbar_breadcrumb' style='float:none; width:auto; padding:8px 0 3px 0; border: 0; border-top: 1px solid #666666;'>
<a id='session4' name='session4'></a><h3>Block 4</h3>
<h3>Wednesday, 08/June/2022: 9:00am - 12:00pm</h3>
</div>
<div class='topline_gray' style='padding:3px;'>
<div class="paper"><span class="paper_time_value">9:00am - 9:07am</span><br /><p class="paper_title">Fun With IIIF</p>
<p class="paper_author"> <u>Tristan Roddis</u></p>

<p class="paper_organisation">Cogapp, United Kingdom</p>

<div ><div class="paper">

<p class="paper_abstract">Give me your fun, your frivolous,</p>
<p class="paper_abstract">Your huddled experiments yearning to breathe free,</p>
<p class="paper_abstract">The wretched refuse of your latest hackathons.</p>
<p class="paper_abstract">Send these, the lightheartedness, tempest-tost to me,</p>
<p class="paper_abstract">I lift my image server beside the golden door!</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">9:07am - 9:14am</span><br /><p class="paper_title">Mapping Color in History: Using IIIF to Annotate Historical Objects with Pigment Data</p>
<p class="paper_author"> <u>Cole Daniel Crawford</u></p>

<p class="paper_organisation">Harvard University Arts and Humanities Research Computing, United States of America</p>

<div ><div class="paper">

<p class="paper_abstract">Mapping Color in History (MCH) is a digital humanities project which examines scientific data drawn from material analyses of pigments in Asian paintings from a historical perspective. Existing pigment databases and publications are centered around the pigment and are difficult to use for non-specialists. MCH builds on this pigment and element data which has been collected by art conservation scientists during XRF, infrared, and Raman forensic analyses, but makes it easier for art history researchers to use the data. MCH also goes further than existing pigment databases by foregrounding the historical objects and presenting scientific pigment data in that context. Each work in the platform includes extensive bibliographic and art history metadata. This facilitates geospatial and temporal analyses, such as tracking where and when pigments first became available to artists by plotting their appearances on maps and timelines.</p>
<p class="paper_abstract">The visual display of information is central to Mapping Color in History. IIIF is a natural technology to use for a project which relies on visual works from numerous museum and library digital collections. Some institutions, such as the Harvard Art Museums, already provide resources via IIIF, and these were easy to integrate into MCH. However, many other institutions do not yet provide IIIF resources. MCH utilizes a new IIIF ingest pipeline provided by the Harvard Library Technical Services team (LTS) which provides image servers and infrastructure as a service to numerous university clients. This centralized IIIF infrastructure allows new projects across the university to integrate IIIF rapidly while staying focused on application features rather than IIIF-specific implementation details and maintenance. Our process starts by securing image rights from a holding institution and obtaining high resolution files. Mapping Color researchers provide the image files and associated metadata. The MCH application deposits the images in an S3 bucket, generates a manifest, validates the manifest, and submits an ingest request to the LTS ingest service via JSON endpoint with JWT authentication. The ingest service then creates and activates URNs for the manifest and all referenced assets and serves images and manifests.</p>
<p class="paper_abstract">IIIF also allows us to deeply integrate pigment analysis data with the object digital representations. Mapping Color in History uses a CatchPy annotation server, which allows researchers to annotate analyses as layers on a canvas representing the work. We have extended the Mirador 3 mirador-annotations plugin to include an adapter for CatchPy and to allow researchers to also capture the visible color and analysis methodology associated with each annotation point. This links the annotations back to our application data, so end users can click on a visible color and have it highlighted within Mirador. The UX is much more usable for researchers and casual users than typical pigment databases, as it is easy to see exactly where pigments appear on the work and compare analyses of different paintings.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">9:14am - 9:21am</span><br /><p class="paper_title">pdiiif: PDF as an offline IIIF Viewer</p>
<p class="paper_author"> <u>Johannes Baiter</u></p>

<p class="paper_organisation">Bavarian State Library</p>

<div ><div class="paper">

<p class="paper_abstract">pdiiif allows users to generate a PDF with a table of contents, a hidden text layer (if the manifest has OCR) and, optionally, annotations from any IIIF manifest. Where possible, this is done using their web browser for the bulk of the work. Compared to other solutions, it is very memory efficient by using a streaming approach that never keeps more than a few pages in memory at once (depending on the browser). Plans for the future include a way to re-import annotations applied to the PDF (e.g. done on an iPad) back into WebAnnotations to bridge the gap between online and offline workflows. At the moment, pdiiif is available as a standalone web application and as a low-footprint JavaScript library that can be embedded in other applications. A Mirador 3 plugin and browser extensions are planned for later in 2022.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">9:21am - 9:51am</span><br /><p class="paper_title">Restoring a Space for Paul Dunbar</p>
<p class="paper_author"> <u>Patrick Cuba</u>, Bryan Haberberger</p>

<p class="paper_organisation">SAINT LOUIS UNIVERSITY, United States of America</p>

<div ><div class="paper">

<p class="paper_abstract">Paul Laurence Dunbar was the first African-American poet to garner national critical acclaim. Born in Dayton, Ohio, in 1872, Dunbar penned a large body of dialect poems, standard English poems, essays, novels, and short stories before he died at the age of 33. His work often addressed the difficulties encountered by members of his race and the efforts of African-Americans to achieve equality in America. He was praised both by the prominent literary critics of his time and his literary contemporaries but the resources related to his works and life are often included in minority author exhibitions, aggregated genre-based collections, or disregarded altogether. The Dunbar Library and Archive (DLA) joins existing remote IIIF collections of images, manuscripts, scores, and performances with textual resources, geographic locations, and bibliographic records. In addition to enriching descriptions and relationships with new annotations, new authority entities are being created for the supporting people, places, and events surrounding his life. Students and community members are coordinating with the U.S. National Parks Service and community groups to digitize many artifacts and resources that are challenging to access. The University of Dayton offers a model for a focused and distributed open archive that offers better representation of the subject and his diverse communities, functions as a research portal for scholars and journalists, and encourages sharing and creation among teachers and members of the public. The team at Saint Louis University is building this data entry platform and public website as a reusable architecture on open and available tools including their TPEN transcription tool, public RERUM repository, as well as IIIF and W3C Web Annotation standards. The first phase of this project completes this August and the public site development continues through June 2023.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">9:51am - 9:58am</span><br /><p class="paper_title">Designing a proof-of-concept for the implementation of the Presentation API 3.0 and Change Discovery API 1.0 within the DaSCH Service Platform (DSP)</p>
<p class="paper_author"> <u>Julien Antoine Raemy</u></p>

<p class="paper_organisation">University of Basel / DaSCH, Switzerland</p>

<div ><div class="paper">

<p class="paper_abstract">The Swiss National Data &amp; Service Center for the Humanities (DaSCH), a IIIF-C full member since 2017 has implemented the Simple Image Presentation Interface (SIPI), a IIIF Image API 3.0 Server that DaSCH maintained with the help of the Digital Humanities Lab of the University of Basel, within the DaSCH Service Platform (DSP), a software framework used for storing, sharing, and working with primary sources and data in the humanities.</p>
<p class="paper_abstract">DaSCH is in the process of designing a proof-of-concept for the deployment of the IIIF Presentation API 3.0 and the IIIF Change Discovery API 1.0, on the basis of the existing resources and projects hosted on DSP. For the Presentation API, templates will be first created manually with the help of the cookbook recipes. Then, scripts enabling the semi-automation for generating IIIF resources will be designed. As for the Change Discovery, DaSCH already provides an Event log of created resources. Thus an assessment on how the ActivityStreams endpoint could be built on top of it will be carried out.</p>
<p class="paper_abstract">The lightning talk will explore the process and challenges involved in deploying these IIIF APIs and how they could be implemented within DSP to allow users to further contextualise cultural heritage resources on and off the platform as well as enabling improved aggregation thereof.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">9:58am - 10:05am</span><br /><p class="paper_title">IIIF - Could it be time to swap the Image for Information?</p>
<p class="paper_author"> <u>Joseph Padfield</u></p>

<p class="paper_organisation">The National Gallery, United Kingdom</p>

<div ><div class="paper">

<p class="paper_abstract">IIIF has been developing now for over 10 years, evolving from a collaborative method for presenting images on the web into a robust, well documented, global framework for sharing and linking images, annotations, video, audio, and soon, hopefully, even 3D models. So it seems about time to start to consider, at what stage might IIIF transition into the International Information Interoperability Framework? This lighting talk will introduce a new simple IIIF Collection and Manifest presentation tool, based around Mirador 3, which uses the existing presentation API to link sets of images to PDF versions of related publications, but also explores how the presentation API could be used, or potentially, extended to share further data sets and also support the presentation of simple interactive tables or even graphs. Pushing even further the idea that the documented structure for IIIF could be reused or extended to share additional types of data and demonstrate a working example of why it could be time to swap &quot;Image&quot; for &quot;Information&quot;.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">10:05am - 10:12am</span><br /><p class="paper_title">Bringing IIIF to the DSpace community</p>
<p class="paper_author"> <u>Michael Spalti</u><sup>1</sup>, Andrea Bollini<sup>2</sup>, Claudio Cortese<sup>2</sup></p>

<p class="paper_organisation"><sup>1</sup>Willamette University, United States of America; <sup>2</sup>4Science, Italy</p>

<div ><div class="paper">

<p class="paper_abstract">Starting with version 7.2 DSpace, provides basic support for IIIF out of box. The work was the result of a joint effort between Willamette University and 4Science. Willamette University had begun work on DSpace version 7 and IIIF as a way to enhance access to digital content that was being hosted on two local systems. A key objective was to replace this existing infrastructure with a single, community-supported solution.  4Science since  2017 had been developing an addon for DSpace  (starting from version 5) to support IIIF, easily integrated  with a set of external Image Servers such as Cantaloupe or Digilib.  On the basis of these experiences,  an effective collaboration  started, aimed at   integrating IIIF support  in the official DSpace codebase. </p>
<p class="paper_abstract">DSpace 7 now allows institutions to upload images in DSpace, getting automatically a IIIF manifest for the item based on item and bitstream (images) level metadata; in this way the  TOC can be easily managed. Ideally, any IIIF compliant image server can be used, although instructions and full configuration examples are provided for Cantaloupe. Experimental support for the IIIF Search API is also available and it is expected to be refined in future releases. </p>
<p class="paper_abstract">The presentation will introduce the available features, the architecture, the tools and strategies that can help institutions to deal with large collections using bulk imports. </p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">10:12am - 10:19am</span><br /><p class="paper_title">An improvement for Video annotation on Mirador</p>
<p class="paper_author"> <u>Kiyonori Nagasaki</u><sup>1</sup>, Jun Homma<sup>2</sup>, Ikki Ohmukai<sup>1</sup></p>

<p class="paper_organisation"><sup>1</sup>The University of Tokyo, Japan; <sup>2</sup>FLX Style</p>

<div ><div class="paper">

<p class="paper_abstract">As a result of the IIIF Presentation API version 3 (henceforth, IIIFv3), we&#39;ve gotten a set of rules for annotating video. However, there is still not enough implementation to treat it easily. Under such situation, Mirador version 3 finally implements the ability to show video. Therefore, we started to develop a function to embed annotations to Mirador version 3&#39;s video. As a result, not only text but also images can be pasted on the video only by writing a JSON file compliant with IIIFv3. This also means that you can re-edit a video that has already been published. In addition, we have improved the subtitle display for ELAN&#39;s WebVTT. This allowed us to improve the interoperability of Video through IIIF.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">10:19am - 10:26am</span><br /><p class="paper_title">Enriched Art with IIIF: Improving searchability of art collections through machine learning</p>
<p class="paper_author"> <u>Alec Van den broeck</u><sup>1,2,3,4</sup>, Steven Verstockt<sup>1,4</sup>, Christophe Verbruggen<sup>1,3</sup>, Pascal Ennaert<sup>2</sup>, Julie Birkholz<sup>1,3</sup></p>

<p class="paper_organisation"><sup>1</sup>University Ghent; <sup>2</sup>Flemish Art Collection; <sup>3</sup>Ghent Centre for Digital Humanities; <sup>4</sup>Imec IDLab</p>

<div ><div class="paper">

<p class="paper_abstract">Art exhibition catalogs provide documentation for items displayed during an exhibition at museums or art galleries. The contents of these catalogs are important for GLAM institutions, as many of the works described in these catalogs are now part of their collections. Moreover, art historians use these catalogs to research the exposition of works, investigate particular curators, galleries, artists, and discover general trends over time. Even though a large portion of the catalogs have been digitized, their contents are not transcribed, making automated processes such as full-text search difficult. And although there exist several end-to-end Optical Character Recognition (OCR) systems which can automate the transcription process, these often require technical knowledge for the selection of pre- and post-processing methods or retraining of the underlying OCR model. Thus the use of these sources remains a largely manual and time-intensive task.</p>
<p class="paper_abstract">During this talk, I will present a semi-automated pipeline which is able to extract metadata from exhibition catalogs. I investigate this using 19th-century art exhibition catalogs of - predominantly Flemish - fine arts museums. This is done by implementing a general OCR model (Tesseract OCR) which is adapted to the characteristics of the art catalogs. The OCR text output is then transformed into IIIF annotations, which can be loaded as part of a IIIF manifest into Madoc - an open source, IIIF-based platform for (participatory) annotation, transcription and showcasing of digital collections. In Madoc, the OCR results can be further corrected by volunteers or domain experts. Afterward, the corrected text data is datamined using machine learning techniques such as Named Entity Recognition (NER) and Document Layout Analysis. The extracted keywords are then linked to external authorities such as RKD Artists and Art and Architecture Thesaurus (AAT). Finally, this linked information is embedded in the IIIF manifest. This method assists in reusing, sharing and querying the extracted information without requiring a heavy technical background. Thanks to this enriched Linked Open Data, art historians will be able to compile exhibition timelines for artworks and discover previously unknown patterns between artworks based on their exhibition history.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">10:26am - 10:33am</span><br /><p class="paper_title">Chronophage: Leveraging IIIF standards to build the CoKL Database</p>
<p class="paper_author"> <u>Aaron David Macks</u></p>

<p class="paper_organisation">Harvard Business Publishing, United States of America</p>

<div ><div class="paper">

<p class="paper_abstract">The Corpus Kalendarium Database, or CoKL DB*, is a relational database of the devotional calendars from Books of Hours. As of February 2022, it contains 376 transcribed calendars and metadata about a further 267 manuscripts, yielding 137,605 calendar entries in total. The project is built from, and only possible with, the large scale manuscript digitization work at repositories worldwide, and the IIIF standard of presenting those digital facsimiles. Although not all of the digital manuscripts added come from IIIF-enabled collections, the standard enables easier discovery and the transcription of those manuscripts. This will be a case study of a big data digital humanities project only possible due to the the wide scale use of the IIIF manifest standard by libraries, museums, and other manuscript holding institutions.</p>
<p class="paper_abstract">* http://www.cokldb.org/</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">10:33am - 10:40am</span><br /><p class="paper_title">DetektIIIF, a IIIF browser extension</p>
<p class="paper_author"> <u>Leander Seige</u></p>

<p class="paper_organisation">seige.digital GbR, Germany</p>

<div ><div class="paper">

<p class="paper_abstract">More and more museums, libraries, galleries, and archives support IIIF and enable scholars and culture enthusiasts to work with data from heterogeneous sources. But, how IIIF content is displayed on web pages, how links to manifests and collections are presented, still varies from institution to institution. Furthermore, copying URLs to JSON files is not a familiar way of working for many users. The detektIIIF browser extension attempts to provide users with consistent, convenient access to IIIF resources on websites. DetektIIIF tries to automatically detect IIIF resources and displays them in an orderly manner. The extension also examines some quality features of IIIF implementations and displays the details. At first, only a prototype version of detektIIIF for Chrome existed for a few years. On the initiative of the Zentralbibliothek Zürich, seige.digital GbR developed a more advanced version of detektIIIF with improved features, compatibility with Firefox and Chrome, and an interface that can be customized through themes for institutional use. DetektIIIF is open source software. This lightning talk demonstrates the functionality and the architecture of the extension, invites to use detektIIIF and to participate in its further development.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">10:40am - 10:47am</span><br /><p class="paper_title">Miiify: distributed crowdsourced annotations</p>
<p class="paper_author"> <u>John Moore</u>, Louise Seaward, Pip Willcox</p>

<p class="paper_organisation">The National Archives, United Kingdom</p>

<div ><div class="paper">

<p class="paper_abstract">Miiify is an experimental annotation server that is based on the W3C Web Annotation Protocol. Rather than rely on running a centralised infrastructure, Miiify adopts a distributed approach to collaboration using a peer review process facilitated on GitHub. Each user interacts with their own instance of Miiify using a web interface that supports annotating content such as images. Contributions are then submitted back to the main GitHub repository through a pull request.</p>
<p class="paper_abstract">Miiify is built using Irmin, a distributed database technology following the same principles as Git. Some key features of Miiify include:</p>
<p class="paper_abstract">• Native Git support (no external database required)</p>
<p class="paper_abstract">• No requirement to support user authentication or accounts</p>
<p class="paper_abstract">• Provenance through Git commit history</p>
<p class="paper_abstract">• Light-weight (Docker image less than 60MB)</p>
<p class="paper_abstract">The ability to read and write data in the Git format means that there is no dependency on an external database technology. The contents of the Git repository (the annotations) can be navigated as a tree structure corresponding directly to the structure of the JSON. Running a dedicated centralised crowdsourcing service requires user account management. This will include governing what privileges users have to alter data on that platform. Using Git means we can take advantage of the identity management available in platforms such as GitHub. GitHub conforms to GDPR regulations by limiting the amount of personal data required to use the service. For example, to contribute on GitHub only a valid email address is required which can provide a level of anonymity for a user. However, any changes to data made by users are visible through the review process these platforms facilitate. The complete history of changes are maintained which allows data to be reverted to any known previous version. Miiify has been built with the OCaml toolchain which compiles to efficient native code capable of running within a light-weight Docker container or even within a unikernel directly on a hypervisor or bare metal.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">10:47am - 10:54am</span><br /><p class="paper_title">An open source, IIIF-enabled, natural history collection platform</p>
<p class="paper_author"> <u>Andy Cummins</u></p>

<p class="paper_organisation">Cogapp, United Kingdom</p>

<div ><div class="paper">

<p class="paper_abstract">With the launch of the Natural History Museum of Denmark&#39;s collection platform (https://collections.snm.ku.dk/en) both researchers and members of the general public can explore the collections in intimate detail from anywhere in the world. There are hundreds of thousands of objects to explore with more being added frequently by the museum.</p>
<p class="paper_abstract">In this lightning talk I will explain how the collection weaves together images and metadata from the museum&#39;s in-house collection management system and the Global Biodiversity Information Facility (GBIF) to serve both the scientific community and the general public.</p>
<p class="paper_abstract">We hope this open source project, launched in partnership with Cogapp last year, can act as a catalyst for other natural history museums and GBIF contributors to present their collections online.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">10:54am - 11:01am</span><br /><p class="paper_title">Transcribing Primary Sources using FairCopy and IIIF</p>
<p class="paper_author"> <u>Nick Laiacona</u></p>

<p class="paper_organisation">Performant Software Solutions LLC, United States of America</p>

<div ><div class="paper">

<p class="paper_abstract">FairCopy is a simple and powerful tool for reading, transcribing, and encoding primary sources using the TEI Guidelines. FairCopy can import IIIF manifests as a starting point for transcription. Users can then highlight zones on each surface and link them to the transcription. FairCopy exports valid TEI XML which is linked back to the original IIIF endpoints. In this lightning talk, we will demonstrate IIIF functionality in FairCopy.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">11:01am - 11:31am</span><br /><p class="paper_title">IIIF as an enabler for presentation and participation in the public history project Gent Gemapt.</p>
<p class="paper_author"> Fien Danniau, <u>Frederic Lamsens</u>, Vincent Ducatteeuw, Lise Foket</p>

<p class="paper_organisation">Ghent Centre for Digital Humanities (Ghent University, Belgium)</p>

<div ><div class="paper">

<p class="paper_abstract">Gent Gemapt (2020-2023) is a public history pilot project that relies on IIIF for the integration, presentation, and participative enrichment of heritage. The premise of Gent Gemapt is that all types of heritage can be mapped and that place is an ideal concept to structure and discover a city’s history. Gent Gemapt aims to merge heritage collections with historical maps in order to connect collections, the urban landscape, and the people of Ghent.</p>
<p class="paper_abstract">Since archival and heritage collections are often fragmented over different GLAMs, we need a consistent way to organise the data. To do this spatially, we create a geographical index - a gazetteer - which uniquely describes each place (e.g. streets, squares, bodies of water, public buildings) with an identifier and additional information. Additionally, IIIF provides a framework to unify collections across GLAMs.</p>
<p class="paper_abstract">In Gent Gemapt, the heritage partners have diverging digital infrastructures, metadata schemes and levels of IIIF implementation, which complicates the extraction of common properties such as dates, references to places, identifiers, coordinates etc. For each contributing partner, we add a metadata mapping service to solve this issue.</p>
<p class="paper_abstract">We use Omeka S as the framework to integrate the gazetteer, the collection data and the historical maps. Places and manifests of collection objects are loaded into Omeka S as items and referenced to each other. Historical maps are georeferenced, converted to tile services and added as Omeka items. An API is built on top of Omeka S to feed a rich user interface where users can navigate through the historical map layers, query the places and explore the collections in IIIF.</p>
<p class="paper_abstract">The next step for Gent Gemapt is to use the Madoc platform to evolve from a presentation platform to a participative one where Ghentians can enrich the location-based collections by enriching metadata, annotating images, transcribing documents, and georeferencing historical maps. Next to presenting the enriched collections in Gent Gemapt, a future challenge will be to let the enriched collections be received and validated by the collection managers as well.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
</div>
<div class='topline_gray' style='padding:3px;'>
<div class="paper"><span class="paper_time_value_error">11:31am - 12:01pm </span><br /><p class="paper_title">From Micrio to Macro: No-code IIIF for museum collections</p>
<p class="paper_author"> <u>Erwin Verbruggen</u>, Marcel Duin</p>

<p class="paper_organisation">Q42, Netherlands</p>

<div ><div class="paper">

<p class="paper_abstract">Visual Storytelling and collections platform Micrio provides a variety of organisations with cloud-based IIIF capabilities. In fields as diverse as aeronautics, journalism, e-commerce and cultural heritage, it is a “no-code” solution for both showing high- and ultra-high resolution images online and for adding story formats to them.</p>
<p class="paper_abstract">In this presentation, we outline some of the developments Micrio underwent since last year’s conference. Its infrastructure was rebuilt from the ground up, resulting in an edge-based IIIF image server. Micrio now loads arguably the world’s largest digitised art work, Rembrandt’s 717 Gigapixel Night Watch, in a matter of milliseconds.</p>
<p class="paper_abstract">Case: IIIF Edge-based WebAssembly servers</p>
<p class="paper_abstract">In 2021, Micrio created a WebAssembly-based IIIF Image API processor, which runs as an edge-service. Any IIIF Image API call is handled as close as possible to the API requester, on a fully decentralized system. The processing takes place in a single worker sandbox provided by CloudFlare, and is only active for the duration of the request.</p>
<p class="paper_abstract">No more monolithic single instance image server, or even distributed docker VMs; the edge-based solution is a truly infinitely scaling one that also optimizes the cost structure. We will demonstrate how this works, how offloading and caching is handled, and discuss advantages and future improvements of this project.</p>


</div>
</div>
</div>
</div>
<div class='navbar_breadcrumb' style='float:none; width:auto; padding:8px 0 3px 0; border: 0; border-top: 1px solid #666666;'>
<a id='session5' name='session5'></a><h3>Block 5</h3>
<h3>Wednesday, 08/June/2022: 1:30pm - 3:30pm</h3>
</div>
<div class='topline_gray' style='padding:3px;'>
<div class="paper"><span class="paper_time_value">1:30pm - 2:00pm</span><br /><p class="paper_title">Reaching out to the crowds: IIIF as a scholarly practice</p>
<p class="paper_author"> <u>Anna Keller</u>, <u>Elias Kreyenbühl</u></p>

<p class="paper_organisation">Zentralbibliothek Zürich, Switzerland</p>

<div ><div class="paper">

<p class="paper_abstract">We believe that IIIF has a huge potential for scholars of the (digital) humanities which might not yet have been exploited. User-created IIIF collections could serve as a means to make accessible and share research data, which could ultimately lead to a more open scholarly practice surrounding the whole data life cycle. From a UX perspective, we identified two main hurdles: first, IIIF tools have to be integrated better in order to serve a possibly seamless user experience as well as to support scholars in “getting-the-job-done”. Secondly, among humanities scholars, there might be a lack of awareness of the potentials of IIIF tools which might derive from relatively high technical barriers with little benefit for users having only little or no technical knowledge.</p>
<p class="paper_abstract">We developed our use case “Storing and sharing user-created IIIF collections” from those considerations, with the goal to make use of tools and components developed by the IIIF community, and to create a Mirador Viewer workspace usable for an audience with little or no tech-background. Our solution design is as followed:</p>
<p class="paper_abstract">1. A Mirador Viewer serves as central workspace which can be directly accessed from e-manuscripta and e-rara</p>
<p class="paper_abstract">2. Users coming from those platforms can gather IIIF manifests in the same Mirador instance</p>
<p class="paper_abstract">3. The browser-plugin ZB-detektIIIF by Leander Seige and the ZB-Lab is a tool that allows users to create IIIF collections in JSON-format</p>
<p class="paper_abstract">4. For autumn 2022, the development of a storage plugin is planned with API to GitHub to allow users to store and share their IIIF collections</p>
<p class="paper_abstract">With this presentation we would like to showcase the possible potential</p>
<p class="paper_abstract">a) of IIIF collections as a means for an Open Scholarly practice (including the ensuing technical aspects)</p>
<p class="paper_abstract">b) of how to better represent scholarly real world scenarios in a IIIF environment (including the whole data life cycle)</p>
<p class="paper_abstract">c) of the Mirador Viewer as an integration platform for distributed IIIF components within an organizational digital heritage setting</p>
<p class="paper_abstract">d) of widening the audience through a holistic user experience including user flow and awareness.</p>
<p class="paper_abstract">About the authors:</p>
<p class="paper_abstract">The ZB-Lab of the Zentralbibliothek Zürich (Central Library Zurich) was only recently founded with the goal to make our digital assets more accessible and usable for a wider audience. With its dual role as public and research library, the ZB Zurich wants to address respective user groups equally, hoping to bring forward the digital turn in a user-friendly way whilst benefiting from higher user interaction. The main function of the ZB-Lab therefore is to search, find, and create digital service solutions that take into account the potential of the ZB’s digital assets as well as its user needs.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">2:00pm - 2:30pm</span><br /><p class="paper_title">IIIF A/V in Practice: An Overview of IIIF Usage in Avalon Media System</p>
<p class="paper_author"> <u>Jon Cameron</u>, <u>Dananji Withana</u></p>

<p class="paper_organisation">Indiana University Libraries, United States of America</p>

<div ><div class="paper">

<p class="paper_abstract">Avalon Media System is an open source system for managing and providing access to collections of digital audio and video based on the Samvera technology stack. In use at over a dozen institutions, IIIF support has become an important part of Avalon’s strategy for the presentation of digital media assets and interoperability with other digital repository systems. To this end, IIIF APIs have become key players across components within the application.</p>
<p class="paper_abstract">In this session we will share an overview of IIIF integration and usage across software developed by and with the Avalon team. This includes IIIF Presentation 3 manifest generation for digital objects in Avalon Media System; development on the IIIF Timeliner tool and its integration into Avalon; a new video player designed for rich presentation of IIIF Presentation 3 manifests, built using React and Video.js; and contributions to community cookbook recipes and use cases for IIIF APIs.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">2:30pm - 3:00pm</span><br /><p class="paper_title">AMPlifying Interoperability: IIIF Integrations for the Audiovisual Metadata Platform</p>
<p class="paper_author"> <u>Shawn Averkamp</u><sup>1</sup>, <u>Jon Cameron</u><sup>2</sup></p>

<p class="paper_organisation"><sup>1</sup>AVP; <sup>2</sup>Indiana University Libraries</p>

<div ><div class="paper">

<p class="paper_abstract">Since 2018, the Indiana University (IU) Libraries have been working with partners at AVP, New York Public Library (NYPL), and the University of Texas at Austin, with support from the Andrew W. Mellon Foundation, to build the Audiovisual Metadata Platform, or AMP. AMP is an open-source software platform that allows archivists and librarians to define and execute custom workflows that combine artificial intelligence and machine learning services with human expertise in order to more efficiently and effectively create metadata in support of discovery, identification, navigation, and rights determination. One of the features of AMP is the ability for implementers to add their own “adapters,” which could be additional machine learning tools or data output generators that map from AMPs internal JSON schema to another data format, such as IIIF. In this session, we will share an overview of the AMP platform, illustrate potential use cases for implementation, demonstrate the use of the Avalon project’s IIIF-based Timeliner tool for output correction, and discuss the potential of AMP for exporting machine learning annotations as IIIF manifests for use in emerging audiovisual platforms and players that support the IIIF Annotation format, such as AudiAnnotate and Aviary.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
<hr noshade width="100%" class="float_left"><br /><div class="paper"><span class="paper_time_value">3:00pm - 3:30pm</span><br /><p class="paper_title">Clover: a minimal IIIF viewer for Image, Sound, and Video canvases</p>
<p class="paper_author"> <u>Adam Arling</u>, <u>Mat Jordan</u></p>

<p class="paper_organisation">Northwestern University</p>

<div ><div class="paper">

<p class="paper_abstract">How would you present a two-part film from the 1950s alongside images of the original film and the cover material in a single manifest? Conceived during an A/V migration project at Northwestern University Libraries showcasing items requiring both streaming time-based media and pan-zoomable image resources, Clover IIIF is a minimal viewer that delivers optimal user interaction with multi-canvas manifests containing Image, Sound, and Video content resource types. In this presentation, Adam and Mat will demonstrate unique use-cases for the viewer, customization options, some limitations, and a proposed roadmap.</p>
<p class="paper_abstract"></p>

</div>
</div>
</div>
</div>
</div>



[showcase]: {{ site.root_url | absolute_url }}/event/2022/cambridge/showcase
